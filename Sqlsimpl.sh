#!/data/data/com.termux/files/usr/bin/bash
# ðŸ” Sqlsimpl.sh â€” Auto SQLMap Crawler + URL Extractor
# ðŸ§  Coded by Sriram | GitHub: https://github.com/sunnamsriram1
# ðŸ“¦ Requirement: sqlmap in the same folder (e.g., ~/SqlmapS/sqlmap/sqlmap.py)

# ðŸŽ¨ Colors
GREEN="\033[1;32m"
RED="\033[1;31m"
CYAN="\033[1;36m"
YELLOW="\033[1;33m"
NC="\033[0m" # No color

clear
echo -e "${CYAN}ðŸ›¡ï¸ Simple SQLMap Auto-Crawler Script â€” Coded by Sriram${NC}"
echo -e "${YELLOW}ðŸ”— Enter target URL (e.g., http://site.com): ${NC}"
read target

# âœ… Validate input
if [[ -z "$target" ]]; then
    echo -e "${RED}[âœ˜] No URL entered! Exiting...${NC}"
    exit 1
fi

# ðŸ“ Output files
OUTFILE="crawled_urls.txt"
TMPFILE="tmp_sqlmap_output.txt"

# ðŸ•·ï¸ Crawl with sqlmap
echo -e "${GREEN}[âœ“] Crawling: $target using sqlmap...${NC}"
python3 sqlmap.py -u "$target" --crawl=2 --batch > "$TMPFILE" 2>&1

# ðŸ” Extract query parameter URLs (id, nid, cat, pid, etc.)
echo -e "${YELLOW}[i] Extracting URLs with parameters from SQLMap output...${NC}"
grep -oE 'http[s]?://[^ ]+\?(id|nid|pid|page|cat|newsid)=[^ ]+' "$TMPFILE" | sort -u > "$OUTFILE"

# âœ… Result summary
if [[ -s "$OUTFILE" ]]; then
    echo -e "${GREEN}[âœ“] Extracted URLs saved to: $OUTFILE${NC}"
    cat "$OUTFILE"
else
    echo -e "${RED}[âœ˜] No vulnerable-style URLs found.${NC}"
fi

# ðŸ§¹ Clean up
rm "$TMPFILE"
